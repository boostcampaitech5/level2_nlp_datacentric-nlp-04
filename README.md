# level2_nlp_datacentric-nlp-04

## ğŸ›ï¸ Data Controll Center
### 1. ì‹¤í–‰ ë°©ë²•
1. `main.py` ë‚´ì— `FILE_PATH` ë³€ìˆ˜ë¥¼ ì„¤ì • í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤. 
2. ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ dependencyë¥¼ ì„¤ì¹˜ í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤. 

```
pip install streamlit
pip install matplotlib
apt-get install fonts-nanum*
```

3. ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 

```
streamlit run main.py --server.port PORT_NUMBER
```
### 2. ì˜¤ë¥˜ ë°œìƒì‹œ
#### 1. í°íŠ¸ë¥¼ ì„¤ì¹˜í•˜ì˜€ìœ¼ë‚˜ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ í•˜ëŠ” ê²½ìš°. 

- upstage ì„œë²„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰ ì‹œì¼œë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. 

```
rm -rf /opt/ml/.cache/matplotlib
```

#### 2. "1. ì‹¤í–‰ ë°©ë²•" 3ë²ˆì—ì„œ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°. 

- ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ ì‹¤í–‰ ì‹œì¼œë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. 

```
streamlit run main.py --server.port PORT_NUMBER --server.fileWatcherType none
```

### 3. Function
#### Easy Miss Label Filtering
![Miss Label Filtering](/Images/easy_miss_label_filter.gif)
- `Class Percentile` Valueë¥¼ ì¡°ì ˆí•´ì„œ, Miss Labelì˜ ë³€ê²½ì„ ê´€ì°°í•˜ì„¸ìš”!
- `OOD(Out of Distribution)` ì„ ì œì™¸í•˜ê³ , Miss Labelì´ Filteringëœ Dataë¥¼ ì‰½ê²Œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”!
- í•´ë‹¹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„ , Miss Label Filteringì„ ì‹œí–‰í•  ë°ì´í„°ì˜ ì˜ˆì¸¡í™•ë¥ ì´ í•„ìš”í•©ë‹ˆë‹¤.
  - ì•„ë˜ì˜ ì½”ë“œë¥¼ í•™ìŠµ ì½”ë“œ ì¶”ê°€í•´ì£¼ì„¸ìš”.
      - ë§¨ ìœ„ Directory Path ì •ì˜ êµ¬ê°„
      ```python
      PREDICT_DIR = os.path.join(BASE_DIR, "prediction") if os.path.exists(os.path.join(BASE_DIR, "prediction")) else os.mkdir(os.path.join(BASE_DIR, "prediction"))
      ```
      - ë§¨ ì•„ë˜ í•™ìŠµì´ ì¢…ë£Œëœ í›„ êµ¬ê°„
      ```python
      model.eval()
      preds = []
      for idx, sample in tqdm(dataset_train.iterrows(), # tqdm ì‚¬ìš© ì•ˆí•  ì‹œì— ì‚­ì œ
                              total=len(dataset_train),
                              desc='Predicting'):
          inputs = tokenizer(sample['text'],
                            max_length=128,
                            padding="max_length",
                            return_tensors="pt").to(DEVICE)
          with torch.no_grad():
              logits = model(**inputs).logits
              # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()
              pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()
              preds.extend(pred)

      dataset_train['preds_value'] = np.array(preds).tolist()
      dataset_train.to_csv(os.path.join(PREDICT_DIR, 'train_prediction.csv'), index=False)
      ```
      ```python
      model.eval()
      preds = []
      for idx, sample in tqdm(dataset_valid.iterrows(), # tqdm ì‚¬ìš© ì•ˆí•  ì‹œì— ì‚­ì œ
                              total=len(dataset_valid),
                              desc='Predicting'):
          inputs = tokenizer(sample['text'],
                            max_length=128,
                            padding="max_length",
                            return_tensors="pt").to(DEVICE)
          with torch.no_grad():
              logits = model(**inputs).logits
              # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()
              pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()
              preds.extend(pred)

      dataset_valid['preds_value'] = np.array(preds).tolist()
      dataset_valid.to_csv(os.path.join(PREDICT_DIR, 'valid_prediction.csv'), index=False)
      ```