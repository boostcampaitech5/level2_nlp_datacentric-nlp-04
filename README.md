# level2_nlp_datacentric-nlp-04
ëª¨ë¸ë§ ë³€ê²½ ì—†ì´ ë°ì´í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## í”„ë¡œì íŠ¸ ì†Œê°œ
ì—°í•©ë‰´ìŠ¤ì˜ ë‰´ìŠ¤ ì œëª©ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ITê³¼í•™, ê²½ì œ, ì‚¬íšŒ, ìƒí™œë¬¸í™”, ì„¸ê³„, ìŠ¤í¬ì¸ , ì •ì¹˜ ì´ 7ê°œì˜ í´ë˜ìŠ¤ë¡œ ë¶„ë¥˜í•˜ëŠ” í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.  
train.csvì˜ 12%ì—ëŠ” g2p(grapheme to phoneme)ê°€ ì ìš©ë˜ì–´ ë‰´ìŠ¤ ì œëª©ì— ë…¸ì´ì¦ˆê°€ ìˆê³ , 3%ì—ëŠ” í´ë˜ìŠ¤ê°€ ë¬´ì‘ìœ„ë¡œ ë³€ê²½ë˜ëŠ” ë…¸ì´ì¦ˆê°€ ìˆìŠµë‹ˆë‹¤.  
ëª¨ë¸ë§ ë³€ê²½ ì—†ì´ ë°ì´í„°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

## ê°œë°œ ê¸°ê°„
* 23.05.22 - 23.06.01(ì´ 11ì¼)

### ë©¤ë²„ êµ¬ì„± ë° ì—­í• 
* ê³½ë¯¼ì„ : 
* ì´ì¸ê·  : 
* ì„í•˜ë¦¼ : 
* ìµœíœ˜ë¯¼ : 
* í™©ìœ¤ê¸° : 

## ì‹¤í–‰ ë°©ë²•


## ğŸ›ï¸ Data Controll Center
### 1. ì‹¤í–‰ ë°©ë²•
1. `main.py` ë‚´ì— `FILE_PATH` ë³€ìˆ˜ë¥¼ ì„¤ì • í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤. 
2. ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ dependencyë¥¼ ì„¤ì¹˜ í•´ì£¼ì…”ì•¼ í•©ë‹ˆë‹¤. 

```
pip install streamlit
pip install matplotlib
apt-get install fonts-nanum*
```

3. ë‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ ì‹¤í–‰í•˜ì‹œë©´ ë©ë‹ˆë‹¤. 

```
streamlit run main.py --server.port PORT_NUMBER
```
### 2. ì˜¤ë¥˜ ë°œìƒì‹œ
#### 1. í°íŠ¸ë¥¼ ì„¤ì¹˜í•˜ì˜€ìœ¼ë‚˜ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ í•˜ëŠ” ê²½ìš°. 

- upstage ì„œë²„ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰ ì‹œì¼œë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. 

```
rm -rf /opt/ml/.cache/matplotlib
```

#### 2. "1. ì‹¤í–‰ ë°©ë²•" 3ë²ˆì—ì„œ ì‹¤í–‰ë˜ì§€ ì•ŠëŠ” ê²½ìš°. 

- ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ ì´ìš©í•˜ì—¬ ì‹¤í–‰ ì‹œì¼œë³´ì‹œê¸° ë°”ëë‹ˆë‹¤. 

```
streamlit run main.py --server.port PORT_NUMBER --server.fileWatcherType none
```

### 3. Function
#### Easy Miss Label Filtering
![Miss Label Filtering](/Images/easy_miss_label_filter.gif)
- `Class Percentile` Valueë¥¼ ì¡°ì ˆí•´ì„œ, Miss Labelì˜ ë³€ê²½ì„ ê´€ì°°í•˜ì„¸ìš”!
- `OOD(Out of Distribution)` ì„ ì œì™¸í•˜ê³ , Miss Labelì´ Filteringëœ Dataë¥¼ ì‰½ê²Œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”!
- í•´ë‹¹ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„ , Miss Label Filteringì„ ì‹œí–‰í•  ë°ì´í„°ì˜ ì˜ˆì¸¡í™•ë¥ ì´ í•„ìš”í•©ë‹ˆë‹¤.
  - ì•„ë˜ì˜ ì½”ë“œë¥¼ í•™ìŠµ ì½”ë“œ ì¶”ê°€í•´ì£¼ì„¸ìš”.
      - ë§¨ ìœ„ Directory Path ì •ì˜ êµ¬ê°„
      ```python
      PREDICT_DIR = os.path.join(BASE_DIR, "prediction") if os.path.exists(os.path.join(BASE_DIR, "prediction")) else os.mkdir(os.path.join(BASE_DIR, "prediction"))
      ```
      - ë§¨ ì•„ë˜ í•™ìŠµì´ ì¢…ë£Œëœ í›„ êµ¬ê°„
      ```python
      model.eval()
      preds = []
      for idx, sample in tqdm(dataset_train.iterrows(), # tqdm ì‚¬ìš© ì•ˆí•  ì‹œì— ì‚­ì œ
                              total=len(dataset_train),
                              desc='Predicting'):
          inputs = tokenizer(sample['text'],
                            max_length=128,
                            padding="max_length",
                            return_tensors="pt").to(DEVICE)
          with torch.no_grad():
              logits = model(**inputs).logits
              # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()
              pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()
              preds.extend(pred)

      dataset_train['preds_value'] = np.array(preds).tolist()
      dataset_train.to_csv(os.path.join(PREDICT_DIR, 'train_prediction.csv'), index=False)
      ```
      ```python
      model.eval()
      preds = []
      for idx, sample in tqdm(dataset_valid.iterrows(), # tqdm ì‚¬ìš© ì•ˆí•  ì‹œì— ì‚­ì œ
                              total=len(dataset_valid),
                              desc='Predicting'):
          inputs = tokenizer(sample['text'],
                            max_length=128,
                            padding="max_length",
                            return_tensors="pt").to(DEVICE)
          with torch.no_grad():
              logits = model(**inputs).logits
              # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()
              pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()
              preds.extend(pred)

      dataset_valid['preds_value'] = np.array(preds).tolist()
      dataset_valid.to_csv(os.path.join(PREDICT_DIR, 'valid_prediction.csv'), index=False)
      ```
