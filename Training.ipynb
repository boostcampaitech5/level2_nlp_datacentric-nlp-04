{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-Centric NLP 대회: 주제 분류 프로젝트"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from json import loads\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "from tokenization_kobert import KoBertTokenizer\n",
    "\n",
    "from utils import plot_confusion_matrix\n",
    "from filtering import ood_cls_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label_to_num = {'IT과학': 0,\n",
    "\t\t\t\t\t'경제': 1,\n",
    "\t\t\t\t\t'사회': 2,\n",
    "\t\t\t\t\t'생활문화': 3,\n",
    "\t\t\t\t\t'세계': 4,\n",
    "\t\t\t\t\t'스포츠': 5,\n",
    "\t\t\t\t\t'정치': 6}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'output')\n",
    "PREDICT_DIR = os.path.join(BASE_DIR, \"prediction\") if os.path.exists(os.path.join(BASE_DIR, \"prediction\")) else os.mkdir(os.path.join(BASE_DIR, \"prediction\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'monologg/kobert'\n",
    "tokenizer = KoBertTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7).to(DEVICE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\n",
    "dataset_train, dataset_valid = train_test_split(data, test_size=0.3, random_state=SEED)\n",
    "if not os.path.exists(os.path.join(DATA_DIR, \"origin_train.csv\")):\n",
    "    dataset_train.to_csv(os.path.join(DATA_DIR, \"origin_train.csv\"), index=False)\n",
    "if not os.path.exists(os.path.join(DATA_DIR, \"origin_valid.csv\")):\n",
    "    dataset_valid.to_csv(os.path.join(DATA_DIR, \"origin_valid.csv\"), index=False)\n",
    "# dataset_train = pd.read_csv(os.path.join(DATA_DIR, \"processed_train_10.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, 'synthetic_data.txt'), 'r') as f:\n",
    "    txt = f.readline()\n",
    "    while txt:\n",
    "        json_text=loads(txt)\n",
    "        dataset_train = pd.concat([dataset_train, pd.DataFrame([[json_text['text'], label_to_num[json_text['target']]]], columns=['text', 'target'])], ignore_index=True)\n",
    "        txt = f.readline()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        input_texts = data['text']\n",
    "        targets = data['target']\n",
    "        self.inputs = []; self.labels = []\n",
    "        for text, label in zip(input_texts, targets):\n",
    "            tokenized_input = tokenizer(text,\n",
    "                                        max_length=64,\n",
    "                                        padding='max_length',\n",
    "                                        truncation=True,\n",
    "                                        return_tensors='pt')\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'].squeeze(0),  \n",
    "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx].squeeze(0)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = BERTDataset(dataset_train, tokenizer)\n",
    "data_valid = BERTDataset(dataset_valid, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = evaluate.load('f1')\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return f1.compute(predictions=predictions, references=labels, average='macro')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for wandb setting\n",
    "#os.environ['WANDB_DISABLED'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(project=\"data centric\", entity=\"nlp-10\")\n",
    "run.name = \"BaseLine Test Split=0.3,max_len=64,label_2aug100\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    do_predict=True,\n",
    "    logging_strategy='steps',\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_steps=100,\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    learning_rate= 2e-05,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.999,\n",
    "    adam_epsilon=1e-08,\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type='linear',\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_f1',\n",
    "    greater_is_better=True,\n",
    "    seed=SEED,\n",
    "    report_to=\"wandb\",\n",
    "    disable_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=data_train,\n",
    "    eval_dataset=data_valid,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(os.path.join(OUTPUT_DIR, 'checkpoint-2000')).to(DEVICE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for idx, sample in tqdm(dataset_test.iterrows(),\n",
    "                        total=len(dataset_test),\n",
    "                        desc='Predicting'):\n",
    "    inputs = tokenizer(sample['text'],\n",
    "                       max_length=64,\n",
    "                       padding='max_length',\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()\n",
    "        preds.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test['target'] = preds\n",
    "dataset_test.to_csv(os.path.join(PREDICT_DIR, 'output.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For Training Data Analyze"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for idx, sample in tqdm(dataset_train.iterrows(),\n",
    "                        total=len(dataset_train),\n",
    "                        desc='Predicting'):\n",
    "    inputs = tokenizer(sample['text'],\n",
    "                       max_length=64,\n",
    "                       padding='max_length',\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()\n",
    "        pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()\n",
    "        preds.extend(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_train['preds_value'] = np.array(preds).tolist()\n",
    "dataset_train.to_csv(os.path.join(PREDICT_DIR, 'train_prediction.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1.compute(predictions=torch.argmax(torch.tensor(dataset_train['preds_value'].to_list()), dim=1), references=torch.tensor(dataset_train['target'].to_list()), average='macro')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# For Validation Data Analyze"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for idx, sample in tqdm(dataset_valid.iterrows(),\n",
    "                        total=len(dataset_valid),\n",
    "                        desc='Predicting'):\n",
    "    inputs = tokenizer(sample['text'],\n",
    "                       max_length=64,\n",
    "                       padding='max_length',\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()\n",
    "        pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()\n",
    "        preds.extend(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_valid['preds_value'] = np.array(preds).tolist()\n",
    "dataset_valid.to_csv(os.path.join(PREDICT_DIR, 'valid_prediction.csv'), index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_valid"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1.compute(predictions=torch.argmax(torch.tensor(dataset_valid['preds_value'].to_list()), dim=1), references=torch.tensor(dataset_valid['target'].to_list()), average='macro')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Synthetic Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "synthetic_data = pd.DataFrame(columns=['text', 'target'])\n",
    "with open(os.path.join(DATA_DIR, 'synthetic_data.txt'), 'r') as f:\n",
    "    txt = f.readline()\n",
    "    while txt:\n",
    "        json_text=loads(txt)\n",
    "        synthetic_data = pd.concat([synthetic_data, pd.DataFrame([[json_text['text'], label_to_num[json_text['target']]]], columns=['text', 'target'])], ignore_index=True)\n",
    "        txt = f.readline()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "for idx, sample in tqdm(synthetic_data.iterrows(),\n",
    "                        total=len(synthetic_data),\n",
    "                        desc='Predicting'):\n",
    "    inputs = tokenizer(sample['text'],\n",
    "                       max_length=64,\n",
    "                       padding='max_length',\n",
    "                       truncation=True,\n",
    "                       return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        # pred = torch.argmax(torch.nn.Softmax(dim=1)(logits), dim=1).cpu().numpy()\n",
    "        pred = torch.nn.Softmax(dim=1)(logits).cpu().numpy()\n",
    "        preds.extend(pred)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "synthetic_data['preds'] = preds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "synthetic_data['pred_idx'] = torch.argmax(torch.tensor(preds), dim=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "synthetic_data[synthetic_data['pred_idx'] != synthetic_data['target']]"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
